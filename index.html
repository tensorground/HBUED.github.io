<!DOCTYPE html>
<html lang="en">
<head>
    <meta name="title" content="HBUED: A Large-scale EEG Dataset for Emotion Recognition" />
    <meta name="keywords" content="HBUED, EEG, emotion recognition, dataset, deep learning" />
    <meta name="author" content="Hebei University Research Team" />
    <meta name="description" content="HBUED is a large-scale EEG dataset designed for emotion recognition research, providing a rich collection of emotional EEG data from 50 participants." />
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />

    <link rel="stylesheet" type="text/css" title="Red" href="css/style_red.css" />

    <title>HBUED: A Large-scale EEG Dataset for Emotion Recognition</title>
</head>

<body>
<div id="header">
    <div id="header_inner" class="fixed">
        <div id="logo">
            <h1>HBUED <span class="small-font">Hebei University Emotional EEG Dataset</span></h1>
            <h2>A Large-scale EEG Dataset for Emotion Recognition Research</h2>
        </div>
        <div id="menu">
            <ul>
                <li><a href="index.html">Home</a></li>
                <li><a href="description.html" class="active">Dataset Description</a></li>
                <li><a href="download.html" class="active">Download</a></li>
            </ul>
        </div>
    </div>
</div>

<div id="main">
    <div id="main_inner" class="fixed">
        <div id="primaryContent_columnless">
            <div id="columnA_columnless">
                
                <h3>Abstract</h3>
                <p>We have provided a large-scale affective dataset for analyzing human emotional states. This dataset documents the electroencephalogram (EEG) data of 50 participants from Hebei University (24 males, 26 females). The brain signals were recorded throughout the experiment using a 32-channel EEG device at a sampling rate of 1000Hz, with the impedance kept below 5 kΩ during the experiment. The experiment was divided into four sections, with breaks given to the participants after each section, which they could use for rest and adjustment, or terminate early if needed. Each section consisted of six trials, with each trial including a 5-second cue signaling the start of the trial, followed by a two-minute video clip. Upon the conclusion of the video, the system automatically transitioned to a self-assessment interface, where participants rated each video on valence and arousal levels without any time limit. The detailed protocol is as follows:</p>
                <img src="./img/1.png"  style="width: 50%; height: 50%; display: block; margin-left: auto; margin-right: auto;">


                <h3>illustrate</h3>
                <p>This dataset is publicly available, and we encourage other researchers to use it to test their own affect estimation methods. The dataset was first introduced in the following paper: HBUED: An EEG Dataset for Emotion Recognition.</p>

                
            </div>
        </div>
        <br class="clear" />
    </div>
</div>

<div id="footer" class="fixed">
    <p>Copyright © 2024 Hebei University</p>
</div>

</body>
</html>